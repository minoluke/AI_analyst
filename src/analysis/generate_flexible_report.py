"""
LLMãƒ™ãƒ¼ã‚¹ã®æŸ”è»Ÿãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import os
from datetime import datetime
from typing import Optional
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from src.api import get_openai_response

class FlexibleReportGenerator:
    """LLMã‚’æ´»ç”¨ã—ãŸæ‹¡å¼µæ€§ã®é«˜ã„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    def __init__(self):
        self.timestamp = datetime.now()
    
    def generate_report(self, 
                       results_file: str, 
                       report_type: str = "executive_summary",
                       language: str = "japanese",
                       custom_requirements: Optional[str] = None) -> str:
        """
        æŸ”è»Ÿãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        
        Args:
            results_file: çµæœJSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            report_type: ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆexecutive_summary, technical_detail, action_itemsç­‰ï¼‰
            language: è¨€èªï¼ˆjapanese, englishç­‰ï¼‰
            custom_requirements: ã‚«ã‚¹ã‚¿ãƒ è¦æ±‚äº‹é …
        """
        
        # çµæœãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—åˆ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
        report_prompts = {
            "executive_summary": "çµŒå–¶å±¤å‘ã‘ã®ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ï¼ˆãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤é‡è¦–ï¼‰",
            "technical_detail": "æŠ€è¡“è€…å‘ã‘ã®è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆçµ±è¨ˆæ‰‹æ³•ãƒ»å®Ÿè£…è©³ç´°å«ã‚€ï¼‰",
            "action_items": "å®Ÿè¡Œå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆé †ä½ä»˜ãï¼‰",
            "visual_insights": "è¦–è¦šçš„ã«ç†è§£ã—ã‚„ã™ã„ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆã‚°ãƒ©ãƒ•èª¬æ˜ä»˜ãï¼‰",
            "stakeholder_update": "ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼å‘ã‘é€²æ—å ±å‘Šæ›¸",
            "custom": custom_requirements or "æ¨™æº–çš„ãªãƒ¬ãƒãƒ¼ãƒˆ"
        }
        
        # è¨€èªè¨­å®š
        language_instructions = {
            "japanese": "æ—¥æœ¬èªã§ã€æ•¬èªã‚’ä½¿ç”¨ã—ã€ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã¨ã—ã¦é©åˆ‡ãªå½¢å¼ã§",
            "english": "In professional English with clear structure",
            "chinese": "ç”¨ä¸“ä¸šçš„ä¸­æ–‡æ’°å†™",
            "mixed": "æ—¥æœ¬èªãƒ¡ã‚¤ãƒ³ã§é‡è¦ãªå°‚é–€ç”¨èªã¯è‹±èªä½µè¨˜"
        }
        
        # LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt = f"""
ä»¥ä¸‹ã®åˆ†æçµæœã‹ã‚‰ã€{report_prompts.get(report_type, report_prompts['custom'])}ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€è¨€èªè¦ä»¶ã€‘
{language_instructions.get(language, language_instructions['japanese'])}ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æçµæœãƒ‡ãƒ¼ã‚¿ã€‘
{json.dumps(results, ensure_ascii=False, indent=2)}

ã€ãƒ¬ãƒãƒ¼ãƒˆè¦ä»¶ã€‘
1. èª­ã¿æ‰‹ã«åˆã‚ã›ãŸé©åˆ‡ãªãƒˆãƒ¼ãƒ³ã¨è©³ç´°åº¦
2. é‡è¦ãªç™ºè¦‹ã‚’å¼·èª¿
3. å®Ÿç”¨çš„ãªæ´å¯Ÿã‚’å«ã‚ã‚‹
4. å¿…è¦ã«å¿œã˜ã¦å›³è¡¨ã®èª¬æ˜ã‚’å«ã‚ã‚‹ï¼ˆå®Ÿéš›ã®å›³è¡¨ã¯ç”Ÿæˆä¸è¦ï¼‰
5. æ˜ç¢ºãªæ§‹é€ ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†ã‘ï¼‰

{f"ã€è¿½åŠ è¦ä»¶ã€‘{custom_requirements}" if custom_requirements else ""}

ã€å‡ºåŠ›å½¢å¼ã€‘
ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ã€ä»¥ä¸‹ã®æ§‹é€ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- ã‚¿ã‚¤ãƒˆãƒ«
- ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰
- ä¸»è¦ãªç™ºè¦‹
- è©³ç´°åˆ†æï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
- æ¨å¥¨äº‹é …
- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
"""
        
        # LLMå‘¼ã³å‡ºã—
        report_content = get_openai_response(prompt)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
        metadata = f"""
---
ç”Ÿæˆæ—¥æ™‚: {self.timestamp.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—: {report_type}
è¨€èª: {language}
ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {os.path.basename(results_file)}
---

"""
        
        return metadata + report_content
    
    def generate_comparison_report(self, 
                                 results_files: list,
                                 comparison_focus: str = "performance") -> str:
        """è¤‡æ•°ã®çµæœã‚’æ¯”è¼ƒã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        all_results = {}
        for file_path in results_files:
            with open(file_path, 'r', encoding='utf-8') as f:
                all_results[os.path.basename(file_path)] = json.load(f)
        
        comparison_prompts = {
            "performance": "å„å®Ÿè¡Œã®æ€§èƒ½æ¯”è¼ƒï¼ˆåŠ¹æœã‚µã‚¤ã‚ºã€æœ‰æ„æ€§ç­‰ï¼‰",
            "hypothesis_quality": "ä»®èª¬ã®å“è³ªã¨æ”¹è‰¯åº¦åˆã„ã®æ¯”è¼ƒ",
            "time_efficiency": "å®Ÿè¡Œæ™‚é–“ã¨ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã®æ¯”è¼ƒ",
            "business_impact": "ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®æ¯”è¼ƒ"
        }
        
        prompt = f"""
è¤‡æ•°ã®åˆ†æçµæœã‚’æ¯”è¼ƒã—ã¦ã€{comparison_prompts.get(comparison_focus, 'ç·åˆçš„ãªæ¯”è¼ƒ')}ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã€‘
{json.dumps(all_results, ensure_ascii=False, indent=2)}

ã€ãƒ¬ãƒãƒ¼ãƒˆè¦ä»¶ã€‘
1. å„çµæœã®ä¸»è¦æŒ‡æ¨™ã‚’è¡¨å½¢å¼ã§æ¯”è¼ƒ
2. æ”¹å–„ç‚¹ã¨åŠ£åŒ–ç‚¹ã‚’æ˜ç¢ºã«æŒ‡æ‘˜
3. ãƒˆãƒ¬ãƒ³ãƒ‰ã‚„å‚¾å‘ã®åˆ†æ
4. æœ€ã‚‚åŠ¹æœçš„ã ã£ãŸæ‰‹æ³•ã®ç‰¹å®š
5. ä»Šå¾Œã®æ”¹å–„ææ¡ˆ

æ—¥æœ¬èªã§ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
        
        return get_openai_response(prompt)
    
    def generate_custom_analysis(self, 
                               results_file: str,
                               analysis_questions: list) -> str:
        """ã‚«ã‚¹ã‚¿ãƒ è³ªå•ã«åŸºã¥ãåˆ†æãƒ¬ãƒãƒ¼ãƒˆ"""
        
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        questions_text = "\n".join([f"{i+1}. {q}" for i, q in enumerate(analysis_questions)])
        
        prompt = f"""
ä»¥ä¸‹ã®åˆ†æçµæœã«ã¤ã„ã¦ã€æŒ‡å®šã•ã‚ŒãŸè³ªå•ã«ç­”ãˆã‚‹å½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æçµæœã€‘
{json.dumps(results, ensure_ascii=False, indent=2)}

ã€å›ç­”ã™ã¹ãè³ªå•ã€‘
{questions_text}

ã€å›ç­”å½¢å¼ã€‘
å„è³ªå•ã«å¯¾ã—ã¦ï¼š
- æ˜ç¢ºãªå›ç­”
- ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæ ¹æ‹ 
- å®Ÿç”¨çš„ãªç¤ºå”†
ã‚’å«ã‚ã¦æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
        
        return get_openai_response(prompt)

# ä½¿ç”¨ä¾‹
def main():
    generator = FlexibleReportGenerator()
    
    # æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    results_dir = "/Users/idenominoru/Desktop/AI_analyst/results"
    result_files = sorted([f for f in os.listdir(results_dir) if f.startswith("ultimate_lite_results_")])
    
    if not result_files:
        print("çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    latest_file = os.path.join(results_dir, result_files[-1])
    
    # 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
    print("ğŸ“Š ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­...")
    executive_report = generator.generate_report(
        latest_file, 
        report_type="executive_summary",
        language="japanese"
    )
    
    # 2. æŠ€è¡“è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("ğŸ”§ æŠ€è¡“è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
    technical_report = generator.generate_report(
        latest_file,
        report_type="technical_detail",
        language="mixed"
    )
    
    # 3. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ç”Ÿæˆ
    print("âœ… ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ç”Ÿæˆä¸­...")
    action_report = generator.generate_report(
        latest_file,
        report_type="action_items",
        language="japanese",
        custom_requirements="å„ªå…ˆåº¦ã¨æœŸé™ã®ç›®å®‰ã‚‚å«ã‚ã¦ãã ã•ã„"
    )
    
    # 4. ã‚«ã‚¹ã‚¿ãƒ åˆ†æ
    print("ğŸ¯ ã‚«ã‚¹ã‚¿ãƒ åˆ†æå®Ÿè¡Œä¸­...")
    custom_questions = [
        "ãƒ¢ãƒã‚¤ãƒ«ã¨ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã®å·®ãŒç”Ÿã˜ã‚‹æ ¹æœ¬åŸå› ã¯ä½•ã‹ï¼Ÿ",
        "æŠ•è³‡å¯¾åŠ¹æœï¼ˆROIï¼‰ã®è¦³ç‚¹ã‹ã‚‰æœ€å„ªå…ˆã§å–ã‚Šçµ„ã‚€ã¹ãæ–½ç­–ã¯ï¼Ÿ",
        "ã“ã®çµæœã‹ã‚‰äºˆæ¸¬ã•ã‚Œã‚‹3ãƒ¶æœˆå¾Œã®çŠ¶æ³ã¯ï¼Ÿ"
    ]
    custom_report = generator.generate_custom_analysis(latest_file, custom_questions)
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    reports = {
        "executive_summary": executive_report,
        "technical_detail": technical_report,
        "action_items": action_report,
        "custom_analysis": custom_report
    }
    
    for report_type, content in reports.items():
        filename = f"/Users/idenominoru/Desktop/AI_analyst/results/reports/{report_type}_{timestamp}.md"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ“ {report_type} ä¿å­˜å®Œäº†: {filename}")
    
    # æœ€åˆã®ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
    print("\n" + "="*60)
    print("ğŸ“Š ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼")
    print("="*60)
    print(executive_report)

if __name__ == "__main__":
    main()