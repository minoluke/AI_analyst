"""
D2D_Data2Dashboard „Çπ„Çø„Ç§„É´„ÅÆÁ≥ªÁµ±ÁöÑÂÆüÈ®ìÂÆüË°å
exp01, exp02, exp03... „ÅÆÂÆüÈöõ„ÅÆÂÆüË£Ö
"""

import json
import asyncio
from typing import Dict, List, Optional
from dataclasses import dataclass
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.api import get_openai_response
from src.config import PROJECT_ID, DATASET_ID
from src.config_analysis import get_analysis_config
from google.cloud import bigquery

@dataclass
class ExperimentResult:
    """ÂÆüÈ®ìÁµêÊûú„ÅÆÊßãÈÄ†"""
    experiment_id: str
    hypothesis_id: str
    control_group_size: int
    treatment_group_size: int
    control_metric: float
    treatment_metric: float
    effect_size: float
    statistical_significance: bool
    confidence_interval: tuple

class SystematicExperimentRunner:
    """D2D„Çπ„Çø„Ç§„É´„ÅÆÁ≥ªÁµ±ÁöÑÂÆüÈ®ìÂÆüË°åÂô®"""
    
    def __init__(self):
        os.environ["GOOGLE_CLOUD_PROJECT"] = PROJECT_ID
        self.client = bigquery.Client(project=PROJECT_ID)
        self.config = get_analysis_config()
    
    def design_experimental_groups(self, hypothesis: Dict) -> Dict:
        """Step 1: ÂÆüÈ®ìÁæ§„ÉªÂØæÁÖßÁæ§„ÅÆÂÖ∑‰ΩìÁöÑË®≠Ë®à"""
        
        design_prompt = f"""
‰ª•‰∏ã„ÅÆ‰ªÆË™¨„Å´ÂØæ„Åó„Å¶„ÄÅA/B„ÉÜ„Çπ„ÉàÈ¢®„ÅÆÂÆüÈ®ìË®≠Ë®à„ÇíË°å„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

„Äê‰ªÆË™¨„Äë
{hypothesis['hypothesis']}

„ÄêË¶ÅÊ±Ç„Äë
1. ÂØæÁÖßÁæ§ÔºàControl GroupÔºâ„ÅÆÂÖ∑‰ΩìÁöÑÂÆöÁæ©
2. ÂÆüÈ®ìÁæ§ÔºàTreatment GroupÔºâ„ÅÆÂÖ∑‰ΩìÁöÑÂÆöÁæ©  
3. ‰∏ªË¶ÅÊàêÂäüÊåáÊ®ôÔºàPrimary MetricÔºâ
4. ÂâØÊ¨°ÊåáÊ®ôÔºàSecondary MetricsÔºâ
5. ÊúÄÂ∞èÊ§úÂá∫ÂäπÊûú„Çµ„Ç§„Ç∫
6. ÂøÖË¶Å„Çµ„É≥„Éó„É´„Çµ„Ç§„Ç∫„ÅÆÊé®ÂÆö

„ÄêÂá∫ÂäõÂΩ¢Âºè„Äë
```json
{{
  "control_group": {{
    "definition": "ÂØæÁÖßÁæ§„ÅÆÂÖ∑‰ΩìÁöÑÊù°‰ª∂",
    "sql_filter": "WHEREÊù°‰ª∂",
    "expected_size": "Êé®ÂÆö„Çµ„É≥„Éó„É´Êï∞"
  }},
  "treatment_group": {{
    "definition": "ÂÆüÈ®ìÁæ§„ÅÆÂÖ∑‰ΩìÁöÑÊù°‰ª∂", 
    "sql_filter": "WHEREÊù°‰ª∂",
    "expected_size": "Êé®ÂÆö„Çµ„É≥„Éó„É´Êï∞"
  }},
  "primary_metric": {{
    "name": "‰∏ªË¶ÅÊåáÊ®ôÂêç",
    "calculation": "ÊåáÊ®ô„ÅÆË®àÁÆóÊñπÊ≥ï",
    "sql_expression": "SQLÂºè"
  }},
  "secondary_metrics": [
    {{
      "name": "ÂâØÊ¨°ÊåáÊ®ôÂêç",
      "calculation": "Ë®àÁÆóÊñπÊ≥ï"
    }}
  ],
  "statistical_approach": {{
    "test_type": "‰ΩøÁî®„Åô„ÇãÁµ±Ë®àÊ§úÂÆö",
    "alpha": 0.05,
    "power": 0.8,
    "minimum_effect_size": "ÊúÄÂ∞èÊ§úÂá∫ÂäπÊûú"
  }}
}}
```
"""
        
        response = get_openai_response(design_prompt)
        return self._extract_json_object(response)
    
    def execute_exp01_basic_analysis(self, hypothesis: Dict, design: Dict) -> ExperimentResult:
        """exp01: Âü∫Êú¨ÁöÑ„Å™Ë®òËø∞Áµ±Ë®àÂàÜÊûê"""
        
        print(f"üî¨ exp01_{hypothesis['id']}_basic_analysis ÂÆüË°å‰∏≠...")
        
        # Âü∫Êú¨Áµ±Ë®àSQLÁîüÊàê
        basic_sql = f"""
        WITH control_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {design['primary_metric']['sql_expression']} as metric_value
          FROM {self.config.get_full_table_reference()}
          WHERE {design['control_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        treatment_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {design['primary_metric']['sql_expression']} as metric_value  
          FROM {self.config.get_full_table_reference()}
          WHERE {design['treatment_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        )
        SELECT 
          'control' as group_type,
          COUNT(*) as sample_size,
          AVG(metric_value) as mean_metric,
          STDDEV(metric_value) as std_metric
        FROM control_group
        UNION ALL
        SELECT 
          'treatment' as group_type,
          COUNT(*) as sample_size, 
          AVG(metric_value) as mean_metric,
          STDDEV(metric_value) as std_metric
        FROM treatment_group
        """
        
        try:
            results = self.client.query(basic_sql).to_dataframe()
            
            control_data = results[results['group_type'] == 'control'].iloc[0]
            treatment_data = results[results['group_type'] == 'treatment'].iloc[0]
            
            effect_size = (treatment_data['mean_metric'] - control_data['mean_metric']) / control_data['mean_metric']
            
            return ExperimentResult(
                experiment_id="exp01_basic",
                hypothesis_id=hypothesis['id'],
                control_group_size=int(control_data['sample_size']),
                treatment_group_size=int(treatment_data['sample_size']),
                control_metric=float(control_data['mean_metric']),
                treatment_metric=float(treatment_data['mean_metric']),
                effect_size=float(effect_size),
                statistical_significance=False,  # exp01„Åß„ÅØÁµ±Ë®àÊ§úÂÆö„Å™„Åó
                confidence_interval=(0, 0)
            )
            
        except Exception as e:
            print(f"‚ùå exp01 ÂÆüË°å„Ç®„É©„Éº: {e}")
            return None
    
    def execute_exp02_comparative_analysis(self, hypothesis: Dict, design: Dict) -> ExperimentResult:
        """exp02: Áµ±Ë®àÁöÑÊØîËºÉÂàÜÊûêÔºàtÊ§úÂÆöÁ≠âÔºâ"""
        
        print(f"üî¨ exp02_{hypothesis['id']}_comparative_analysis ÂÆüË°å‰∏≠...")
        
        # Áµ±Ë®àÊ§úÂÆöÁî®„ÅÆSQLÔºà„Çà„ÇäË©≥Á¥∞„Å™ÂàÜÊûêÔºâ
        comparative_sql = f"""
        WITH control_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {design['primary_metric']['sql_expression']} as metric_value,
            'control' as group_type
          FROM {self.config.get_full_table_reference()}
          WHERE {design['control_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        treatment_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {design['primary_metric']['sql_expression']} as metric_value,
            'treatment' as group_type
          FROM {self.config.get_full_table_reference()}
          WHERE {design['treatment_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        combined_data AS (
          SELECT * FROM control_group
          UNION ALL  
          SELECT * FROM treatment_group
        )
        SELECT 
          group_type,
          COUNT(*) as sample_size,
          AVG(metric_value) as mean_metric,
          STDDEV(metric_value) as std_metric,
          -- ‰ø°È†ºÂå∫ÈñìË®àÁÆóÁî®
          AVG(metric_value) - 1.96 * STDDEV(metric_value)/SQRT(COUNT(*)) as ci_lower,
          AVG(metric_value) + 1.96 * STDDEV(metric_value)/SQRT(COUNT(*)) as ci_upper
        FROM combined_data
        GROUP BY group_type
        """
        
        try:
            results = self.client.query(comparative_sql).to_dataframe()
            
            control_data = results[results['group_type'] == 'control'].iloc[0]
            treatment_data = results[results['group_type'] == 'treatment'].iloc[0]
            
            # „Ç®„Éï„Çß„ÇØ„Éà„Çµ„Ç§„Ç∫Ë®àÁÆó
            effect_size = (treatment_data['mean_metric'] - control_data['mean_metric']) / control_data['mean_metric']
            
            # Áµ±Ë®àÁöÑÊúâÊÑèÊÄßÂà§ÂÆöÔºàË®≠ÂÆöÂÄ§„Çí‰ΩøÁî®Ôºâ
            significance = self.config.is_significant(effect_size)
            
            return ExperimentResult(
                experiment_id="exp02_comparative",
                hypothesis_id=hypothesis['id'],
                control_group_size=int(control_data['sample_size']),
                treatment_group_size=int(treatment_data['sample_size']),
                control_metric=float(control_data['mean_metric']),
                treatment_metric=float(treatment_data['mean_metric']),
                effect_size=float(effect_size),
                statistical_significance=significance,
                confidence_interval=(float(treatment_data['ci_lower']), float(treatment_data['ci_upper']))
            )
            
        except Exception as e:
            print(f"‚ùå exp02 ÂÆüË°å„Ç®„É©„Éº: {e}")
            return None
    
    def execute_exp03_advanced_segmentation(self, hypothesis: Dict, design: Dict) -> ExperimentResult:
        """exp03: È´òÂ∫¶„Å™„Çª„Ç∞„É°„É≥„ÉàÂàÜÊûê"""
        
        print(f"üî¨ exp03_{hypothesis['id']}_advanced_segmentation ÂÆüË°å‰∏≠...")
        
        # „Çª„Ç∞„É°„É≥„ÉàÂà•ÂàÜÊûêSQL
        segmentation_sql = f"""
        WITH control_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {self.config.schema.device_category_field} as device_type,
            {self.config.schema.geo_country_field} as country,
            {design['primary_metric']['sql_expression']} as metric_value,
            'control' as group_type
          FROM {self.config.get_full_table_reference()}
          WHERE {design['control_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        treatment_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {self.config.schema.device_category_field} as device_type,
            {self.config.schema.geo_country_field} as country,
            {design['primary_metric']['sql_expression']} as metric_value,
            'treatment' as group_type
          FROM {self.config.get_full_table_reference()}
          WHERE {design['treatment_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        combined_data AS (
          SELECT * FROM control_group
          UNION ALL
          SELECT * FROM treatment_group  
        )
        SELECT 
          group_type,
          device_type,
          COUNT(*) as sample_size,
          AVG(metric_value) as mean_metric,
          STDDEV(metric_value) as std_metric
        FROM combined_data
        WHERE device_type IS NOT NULL
        GROUP BY group_type, device_type
        ORDER BY device_type, group_type
        """
        
        try:
            results = self.client.query(segmentation_sql).to_dataframe()
            
            # „Éá„Éê„Ç§„ÇπÂà•„ÅÆÂäπÊûú„ÇíÈõÜË®à
            device_effects = []
            for device in results['device_type'].unique():
                device_data = results[results['device_type'] == device]
                if len(device_data) == 2:  # control & treatment ‰∏°ÊñπÂ≠òÂú®
                    control = device_data[device_data['group_type'] == 'control'].iloc[0]
                    treatment = device_data[device_data['group_type'] == 'treatment'].iloc[0]
                    
                    device_effect = (treatment['mean_metric'] - control['mean_metric']) / control['mean_metric']
                    device_effects.append(device_effect)
            
            # ÂÖ®‰Ωì„ÅÆÂπ≥Âùá„Ç®„Éï„Çß„ÇØ„Éà
            overall_effect = sum(device_effects) / len(device_effects) if device_effects else 0
            
            # ÂÖ®‰Ωì„Çµ„É≥„Éó„É´„Çµ„Ç§„Ç∫
            total_control = results[results['group_type'] == 'control']['sample_size'].sum()
            total_treatment = results[results['group_type'] == 'treatment']['sample_size'].sum()
            
            return ExperimentResult(
                experiment_id="exp03_segmentation",
                hypothesis_id=hypothesis['id'],
                control_group_size=int(total_control),
                treatment_group_size=int(total_treatment),
                control_metric=0.0,  # „Çª„Ç∞„É°„É≥„ÉàÂàÜÊûê„Å™„ÅÆ„ÅßÂÄãÂà•ÂÄ§„ÅØÁÑ°ÊÑèÂë≥
                treatment_metric=0.0,
                effect_size=float(overall_effect),
                statistical_significance=self.config.is_significant(overall_effect)
                confidence_interval=(0, 0)
            )
            
        except Exception as e:
            print(f"‚ùå exp03 ÂÆüË°å„Ç®„É©„Éº: {e}")
            return None
    
    def run_systematic_experiments(self, hypothesis: Dict) -> Dict:
        """‰ªÆË™¨„Å´ÂØæ„Åô„ÇãÁ≥ªÁµ±ÁöÑÂÆüÈ®ì„ÅÆÂÆåÂÖ®ÂÆüË°å"""
        
        print(f"\nüöÄ {hypothesis['id']} „ÅÆÁ≥ªÁµ±ÁöÑÂÆüÈ®ìÈñãÂßã")
        
        # Step 1: ÂÆüÈ®ìË®≠Ë®à
        print("üìã Step 1: ÂÆüÈ®ìÁæ§„ÉªÂØæÁÖßÁæ§Ë®≠Ë®à")
        design = self.design_experimental_groups(hypothesis)
        
        if not design:
            print("‚ùå ÂÆüÈ®ìË®≠Ë®à„Å´Â§±Êïó")
            return None
        
        print(f"‚úÖ Ë®≠Ë®àÂÆå‰∫Ü: {design.get('primary_metric', {}).get('name', 'Unknown')}")
        
        # Step 2: 3ÊÆµÈöé„ÅÆÂÆüÈ®ìÂÆüË°å
        results = {}
        
        # exp01: Âü∫Êú¨ÂàÜÊûê
        exp01_result = self.execute_exp01_basic_analysis(hypothesis, design)
        if exp01_result:
            results['exp01'] = exp01_result
            print(f"‚úÖ exp01 ÂÆå‰∫Ü: „Ç®„Éï„Çß„ÇØ„Éà„Çµ„Ç§„Ç∫ {exp01_result.effect_size:.3f}")
        
        # exp02: ÊØîËºÉÂàÜÊûê  
        exp02_result = self.execute_exp02_comparative_analysis(hypothesis, design)
        if exp02_result:
            results['exp02'] = exp02_result
            print(f"‚úÖ exp02 ÂÆå‰∫Ü: ÊúâÊÑèÊÄß {exp02_result.statistical_significance}")
        
        # exp03: „Çª„Ç∞„É°„É≥„ÉàÂàÜÊûê
        exp03_result = self.execute_exp03_advanced_segmentation(hypothesis, design)
        if exp03_result:
            results['exp03'] = exp03_result  
            print(f"‚úÖ exp03 ÂÆå‰∫Ü: „Çª„Ç∞„É°„É≥„ÉàÂäπÊûú {exp03_result.effect_size:.3f}")
        
        return {
            'hypothesis_id': hypothesis['id'],
            'experimental_design': design,
            'experiment_results': results,
            'summary': self._generate_experiment_summary(results)
        }
    
    def _generate_experiment_summary(self, results: Dict) -> str:
        """ÂÆüÈ®ìÁµêÊûú„Çµ„Éû„É™„ÉºÁîüÊàê"""
        
        if not results:
            return "ÂÆüÈ®ìÂÆüË°å„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ"
        
        summary_parts = []
        
        for exp_name, result in results.items():
            summary_parts.append(
                f"{exp_name}: „Ç®„Éï„Çß„ÇØ„Éà„Çµ„Ç§„Ç∫ {result.effect_size:.3f}, "
                f"ÊúâÊÑèÊÄß {'‚óã' if result.statistical_significance else '√ó'}"
            )
        
        return " | ".join(summary_parts)
    
    def _extract_json_object(self, response: str) -> Dict:
        """JSON „Ç™„Éñ„Ç∏„Çß„ÇØ„ÉàÊäΩÂá∫"""
        import re
        
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        
        json_match = re.search(r'(\{.*?\})', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        
        return {}

# ‰ΩøÁî®‰æã
if __name__ == "__main__":
    runner = SystematicExperimentRunner()
    
    # Êó¢Â≠ò„ÅÆ‰ªÆË™¨„ÇíË™≠„ÅøËæº„Åø
    with open('/Users/idenominoru/Desktop/AI_analyst/data/hypotheses/hypotheses_enhanced.json', 'r', encoding='utf-8') as f:
        hypotheses = json.load(f)
    
    # ÊúÄÂàù„ÅÆ‰ªÆË™¨„ÅßÂÆüÈ®ìÂÆüË°å
    if hypotheses:
        result = runner.run_systematic_experiments(hypotheses[0])
        
        # ÁµêÊûú‰øùÂ≠ò
        with open('/Users/idenominoru/Desktop/AI_analyst/results/systematic_experiment_results.json', 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nüéâ Á≥ªÁµ±ÁöÑÂÆüÈ®ìÂÆå‰∫Ü: {result['summary']}")