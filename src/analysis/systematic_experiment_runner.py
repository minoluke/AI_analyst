"""
D2D_Data2Dashboard ã‚¹ã‚¿ã‚¤ãƒ«ã®ç³»çµ±çš„å®Ÿé¨“å®Ÿè¡Œ
exp01, exp02, exp03... ã®å®Ÿéš›ã®å®Ÿè£…
"""

import json
import asyncio
from typing import Dict, List, Optional
from dataclasses import dataclass
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.api import get_openai_response
from src.config import PROJECT_ID, DATASET_ID
from src.config_analysis import get_analysis_config
from google.cloud import bigquery

@dataclass
class ExperimentResult:
    """å®Ÿé¨“çµæœã®æ§‹é€ """
    experiment_id: str
    hypothesis_id: str
    control_group_size: int
    treatment_group_size: int
    control_metric: float
    treatment_metric: float
    effect_size: float
    statistical_significance: bool
    confidence_interval: tuple

class SystematicExperimentRunner:
    """D2Dã‚¹ã‚¿ã‚¤ãƒ«ã®ç³»çµ±çš„å®Ÿé¨“å®Ÿè¡Œå™¨"""
    
    def __init__(self):
        os.environ["GOOGLE_CLOUD_PROJECT"] = PROJECT_ID
        self.client = bigquery.Client(project=PROJECT_ID)
        self.config = get_analysis_config()
    
    def design_experimental_groups(self, hypothesis: Dict) -> Dict:
        """Step 1: å®Ÿé¨“ç¾¤ãƒ»å¯¾ç…§ç¾¤ã®å…·ä½“çš„è¨­è¨ˆ"""
        
        design_prompt = f"""
ä»¥ä¸‹ã®ä»®èª¬ã«å¯¾ã—ã¦ã€A/Bãƒ†ã‚¹ãƒˆé¢¨ã®å®Ÿé¨“è¨­è¨ˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€ä»®èª¬ã€‘
{hypothesis['hypothesis']}

ã€è¦æ±‚ã€‘
1. å¯¾ç…§ç¾¤ï¼ˆControl Groupï¼‰ã®å…·ä½“çš„å®šç¾©
2. å®Ÿé¨“ç¾¤ï¼ˆTreatment Groupï¼‰ã®å…·ä½“çš„å®šç¾©  
3. ä¸»è¦æˆåŠŸæŒ‡æ¨™ï¼ˆPrimary Metricï¼‰
4. å‰¯æ¬¡æŒ‡æ¨™ï¼ˆSecondary Metricsï¼‰
5. æœ€å°æ¤œå‡ºåŠ¹æœã‚µã‚¤ã‚º
6. å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã®æ¨å®š

ã€å‡ºåŠ›å½¢å¼ã€‘
```json
{{
  "control_group": {{
    "definition": "å¯¾ç…§ç¾¤ã®å…·ä½“çš„æ¡ä»¶",
    "sql_filter": "WHEREæ¡ä»¶",
    "expected_size": "æ¨å®šã‚µãƒ³ãƒ—ãƒ«æ•°"
  }},
  "treatment_group": {{
    "definition": "å®Ÿé¨“ç¾¤ã®å…·ä½“çš„æ¡ä»¶", 
    "sql_filter": "WHEREæ¡ä»¶",
    "expected_size": "æ¨å®šã‚µãƒ³ãƒ—ãƒ«æ•°"
  }},
  "primary_metric": {{
    "name": "ä¸»è¦æŒ‡æ¨™å",
    "calculation": "æŒ‡æ¨™ã®è¨ˆç®—æ–¹æ³•",
    "sql_expression": "SQLå¼"
  }},
  "secondary_metrics": [
    {{
      "name": "å‰¯æ¬¡æŒ‡æ¨™å",
      "calculation": "è¨ˆç®—æ–¹æ³•"
    }}
  ],
  "statistical_approach": {{
    "test_type": "ä½¿ç”¨ã™ã‚‹çµ±è¨ˆæ¤œå®š",
    "alpha": 0.05,
    "power": 0.8,
    "minimum_effect_size": "æœ€å°æ¤œå‡ºåŠ¹æœ"
  }}
}}
```
"""
        
        response = get_openai_response(design_prompt)
        return self._extract_json_object(response)
    
    def execute_exp01_basic_analysis(self, hypothesis: Dict, design: Dict) -> ExperimentResult:
        """exp01: åŸºæœ¬çš„ãªè¨˜è¿°çµ±è¨ˆåˆ†æ"""
        
        print(f"ğŸ”¬ exp01_{hypothesis['id']}_basic_analysis å®Ÿè¡Œä¸­...")
        
        # åŸºæœ¬çµ±è¨ˆSQLç”Ÿæˆ
        basic_sql = f"""
        WITH control_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {design['primary_metric']['sql_expression']} as metric_value
          FROM {self.config.get_full_table_reference()}
          WHERE {design['control_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        treatment_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {design['primary_metric']['sql_expression']} as metric_value  
          FROM {self.config.get_full_table_reference()}
          WHERE {design['treatment_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        )
        SELECT 
          'control' as group_type,
          COUNT(*) as sample_size,
          AVG(metric_value) as mean_metric,
          STDDEV(metric_value) as std_metric
        FROM control_group
        UNION ALL
        SELECT 
          'treatment' as group_type,
          COUNT(*) as sample_size, 
          AVG(metric_value) as mean_metric,
          STDDEV(metric_value) as std_metric
        FROM treatment_group
        """
        
        try:
            results = self.client.query(basic_sql).to_dataframe()
            
            control_data = results[results['group_type'] == 'control'].iloc[0]
            treatment_data = results[results['group_type'] == 'treatment'].iloc[0]
            
            effect_size = (treatment_data['mean_metric'] - control_data['mean_metric']) / control_data['mean_metric']
            
            return ExperimentResult(
                experiment_id="exp01_basic",
                hypothesis_id=hypothesis['id'],
                control_group_size=int(control_data['sample_size']),
                treatment_group_size=int(treatment_data['sample_size']),
                control_metric=float(control_data['mean_metric']),
                treatment_metric=float(treatment_data['mean_metric']),
                effect_size=float(effect_size),
                statistical_significance=False,  # exp01ã§ã¯çµ±è¨ˆæ¤œå®šãªã—
                confidence_interval=(0, 0)
            )
            
        except Exception as e:
            print(f"âŒ exp01 å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def execute_exp02_comparative_analysis(self, hypothesis: Dict, design: Dict) -> ExperimentResult:
        """exp02: çµ±è¨ˆçš„æ¯”è¼ƒåˆ†æï¼ˆtæ¤œå®šç­‰ï¼‰"""
        
        print(f"ğŸ”¬ exp02_{hypothesis['id']}_comparative_analysis å®Ÿè¡Œä¸­...")
        
        # çµ±è¨ˆæ¤œå®šç”¨ã®SQLï¼ˆã‚ˆã‚Šè©³ç´°ãªåˆ†æï¼‰
        comparative_sql = f"""
        WITH control_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {design['primary_metric']['sql_expression']} as metric_value,
            'control' as group_type
          FROM {self.config.get_full_table_reference()}
          WHERE {design['control_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        treatment_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {design['primary_metric']['sql_expression']} as metric_value,
            'treatment' as group_type
          FROM {self.config.get_full_table_reference()}
          WHERE {design['treatment_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        combined_data AS (
          SELECT * FROM control_group
          UNION ALL  
          SELECT * FROM treatment_group
        )
        SELECT 
          group_type,
          COUNT(*) as sample_size,
          AVG(metric_value) as mean_metric,
          STDDEV(metric_value) as std_metric,
          -- ä¿¡é ¼åŒºé–“è¨ˆç®—ç”¨
          AVG(metric_value) - 1.96 * STDDEV(metric_value)/SQRT(COUNT(*)) as ci_lower,
          AVG(metric_value) + 1.96 * STDDEV(metric_value)/SQRT(COUNT(*)) as ci_upper
        FROM combined_data
        GROUP BY group_type
        """
        
        try:
            results = self.client.query(comparative_sql).to_dataframe()
            
            control_data = results[results['group_type'] == 'control'].iloc[0]
            treatment_data = results[results['group_type'] == 'treatment'].iloc[0]
            
            # ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚µã‚¤ã‚ºè¨ˆç®—
            effect_size = (treatment_data['mean_metric'] - control_data['mean_metric']) / control_data['mean_metric']
            
            # çµ±è¨ˆçš„æœ‰æ„æ€§åˆ¤å®šï¼ˆè¨­å®šå€¤ã‚’ä½¿ç”¨ï¼‰
            significance = self.config.is_significant(effect_size)
            
            return ExperimentResult(
                experiment_id="exp02_comparative",
                hypothesis_id=hypothesis['id'],
                control_group_size=int(control_data['sample_size']),
                treatment_group_size=int(treatment_data['sample_size']),
                control_metric=float(control_data['mean_metric']),
                treatment_metric=float(treatment_data['mean_metric']),
                effect_size=float(effect_size),
                statistical_significance=significance,
                confidence_interval=(float(treatment_data['ci_lower']), float(treatment_data['ci_upper']))
            )
            
        except Exception as e:
            print(f"âŒ exp02 å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def execute_exp03_advanced_segmentation(self, hypothesis: Dict, design: Dict) -> ExperimentResult:
        """exp03: é«˜åº¦ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ"""
        
        print(f"ğŸ”¬ exp03_{hypothesis['id']}_advanced_segmentation å®Ÿè¡Œä¸­...")
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥åˆ†æSQL
        segmentation_sql = f"""
        WITH control_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {self.config.schema.device_category_field} as device_type,
            {self.config.schema.geo_country_field} as country,
            {design['primary_metric']['sql_expression']} as metric_value,
            'control' as group_type
          FROM {self.config.get_full_table_reference()}
          WHERE {design['control_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        treatment_group AS (
          SELECT 
            {self.config.schema.user_id_field},
            {self.config.schema.device_category_field} as device_type,
            {self.config.schema.geo_country_field} as country,
            {design['primary_metric']['sql_expression']} as metric_value,
            'treatment' as group_type
          FROM {self.config.get_full_table_reference()}
          WHERE {design['treatment_group']['sql_filter']}
            AND {self.config.get_sql_date_filter()}
        ),
        combined_data AS (
          SELECT * FROM control_group
          UNION ALL
          SELECT * FROM treatment_group  
        )
        SELECT 
          group_type,
          device_type,
          COUNT(*) as sample_size,
          AVG(metric_value) as mean_metric,
          STDDEV(metric_value) as std_metric
        FROM combined_data
        WHERE device_type IS NOT NULL
        GROUP BY group_type, device_type
        ORDER BY device_type, group_type
        """
        
        try:
            results = self.client.query(segmentation_sql).to_dataframe()
            
            # ãƒ‡ãƒã‚¤ã‚¹åˆ¥ã®åŠ¹æœã‚’é›†è¨ˆ
            device_effects = []
            for device in results['device_type'].unique():
                device_data = results[results['device_type'] == device]
                if len(device_data) == 2:  # control & treatment ä¸¡æ–¹å­˜åœ¨
                    control = device_data[device_data['group_type'] == 'control'].iloc[0]
                    treatment = device_data[device_data['group_type'] == 'treatment'].iloc[0]
                    
                    device_effect = (treatment['mean_metric'] - control['mean_metric']) / control['mean_metric']
                    device_effects.append(device_effect)
            
            # å…¨ä½“ã®å¹³å‡ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ
            overall_effect = sum(device_effects) / len(device_effects) if device_effects else 0
            
            # å…¨ä½“ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º
            total_control = results[results['group_type'] == 'control']['sample_size'].sum()
            total_treatment = results[results['group_type'] == 'treatment']['sample_size'].sum()
            
            return ExperimentResult(
                experiment_id="exp03_segmentation",
                hypothesis_id=hypothesis['id'],
                control_group_size=int(total_control),
                treatment_group_size=int(total_treatment),
                control_metric=0.0,  # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æãªã®ã§å€‹åˆ¥å€¤ã¯ç„¡æ„å‘³
                treatment_metric=0.0,
                effect_size=float(overall_effect),
                statistical_significance=self.config.is_significant(overall_effect)
                confidence_interval=(0, 0)
            )
            
        except Exception as e:
            print(f"âŒ exp03 å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def run_systematic_experiments(self, hypothesis: Dict) -> Dict:
        """ä»®èª¬ã«å¯¾ã™ã‚‹ç³»çµ±çš„å®Ÿé¨“ã®å®Œå…¨å®Ÿè¡Œ"""
        
        print(f"\nğŸš€ {hypothesis['id']} ã®ç³»çµ±çš„å®Ÿé¨“é–‹å§‹")
        
        # Step 1: å®Ÿé¨“è¨­è¨ˆ
        print("ğŸ“‹ Step 1: å®Ÿé¨“ç¾¤ãƒ»å¯¾ç…§ç¾¤è¨­è¨ˆ")
        design = self.design_experimental_groups(hypothesis)
        
        if not design:
            print("âŒ å®Ÿé¨“è¨­è¨ˆã«å¤±æ•—")
            return None
        
        print(f"âœ… è¨­è¨ˆå®Œäº†: {design.get('primary_metric', {}).get('name', 'Unknown')}")
        
        # Step 2: 3æ®µéšã®å®Ÿé¨“å®Ÿè¡Œ
        results = {}
        
        # exp01: åŸºæœ¬åˆ†æ
        exp01_result = self.execute_exp01_basic_analysis(hypothesis, design)
        if exp01_result:
            results['exp01'] = exp01_result
            print(f"âœ… exp01 å®Œäº†: ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚µã‚¤ã‚º {exp01_result.effect_size:.3f}")
        
        # exp02: æ¯”è¼ƒåˆ†æ  
        exp02_result = self.execute_exp02_comparative_analysis(hypothesis, design)
        if exp02_result:
            results['exp02'] = exp02_result
            print(f"âœ… exp02 å®Œäº†: æœ‰æ„æ€§ {exp02_result.statistical_significance}")
        
        # exp03: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ
        exp03_result = self.execute_exp03_advanced_segmentation(hypothesis, design)
        if exp03_result:
            results['exp03'] = exp03_result  
            print(f"âœ… exp03 å®Œäº†: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŠ¹æœ {exp03_result.effect_size:.3f}")
        
        return {
            'hypothesis_id': hypothesis['id'],
            'experimental_design': design,
            'experiment_results': results,
            'summary': self._generate_experiment_summary(results)
        }
    
    def _generate_experiment_summary(self, results: Dict) -> str:
        """å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        if not results:
            return "å®Ÿé¨“å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
        
        summary_parts = []
        
        for exp_name, result in results.items():
            summary_parts.append(
                f"{exp_name}: ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚µã‚¤ã‚º {result.effect_size:.3f}, "
                f"æœ‰æ„æ€§ {'â—‹' if result.statistical_significance else 'Ã—'}"
            )
        
        return " | ".join(summary_parts)
    
    def _extract_json_object(self, response: str) -> Dict:
        """JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŠ½å‡º"""
        import re
        
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        
        json_match = re.search(r'(\{.*?\})', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        
        return {}

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    runner = SystematicExperimentRunner()
    
    # æ—¢å­˜ã®ä»®èª¬ã‚’èª­ã¿è¾¼ã¿
    with open('/Users/idenominoru/Desktop/AI_analyst/data/hypotheses/hypotheses_enhanced.json', 'r', encoding='utf-8') as f:
        hypotheses = json.load(f)
    
    # æœ€åˆã®ä»®èª¬ã§å®Ÿé¨“å®Ÿè¡Œ
    if hypotheses:
        result = runner.run_systematic_experiments(hypotheses[0])
        
        # çµæœä¿å­˜
        with open('/Users/idenominoru/Desktop/AI_analyst/results/systematic_experiment_results.json', 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ‰ ç³»çµ±çš„å®Ÿé¨“å®Œäº†: {result['summary']}")