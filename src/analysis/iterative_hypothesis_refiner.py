"""
æ®µéšçš„ä»®èª¬æ”¹è‰¯ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆAI-Scientist-v2ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
"""

import json
from typing import Dict, List
from src.api import get_openai_response

class IterativeHypothesisRefiner:
    """æ®µéšçš„ãªä»®èª¬æ”¹è‰¯ãƒ—ãƒ­ã‚»ã‚¹"""
    
    def __init__(self):
        self.refinement_rounds = 2  # æ”¹è‰¯å›æ•°
    
    def generate_initial_hypotheses(self, schema_text: str, data_exploration: str) -> List[Dict]:
        """ã‚¹ãƒ†ãƒƒãƒ—1: åˆæœŸä»®èª¬ç”Ÿæˆ"""
        prompt = f"""
GA4ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰3ã¤ã®åˆæœŸä»®èª¬ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€ãƒ‡ãƒ¼ã‚¿ã€‘
{schema_text}
{data_exploration}

ã€å‡ºåŠ›å½¢å¼ã€‘
```json
[
  {{
    "id": "H001",
    "hypothesis": "æ¤œè¨¼å¯èƒ½ãªä»®èª¬",
    "rationale": "æ ¹æ‹ ",
    "potential_issues": ["æƒ³å®šã•ã‚Œã‚‹å•é¡Œç‚¹"]
  }}
]
```
"""
        
        response = get_openai_response(prompt)
        return self._extract_json(response)
    
    def critical_evaluation(self, hypotheses: List[Dict]) -> List[Dict]:
        """ã‚¹ãƒ†ãƒƒãƒ—2: æ‰¹åˆ¤çš„è©•ä¾¡"""
        evaluation_prompt = f"""
ä»¥ä¸‹ã®ä»®èª¬ã‚’æ‰¹åˆ¤çš„ã«è©•ä¾¡ã—ã€æ”¹å–„ç‚¹ã‚’æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚

ã€ä»®èª¬ã€‘
{json.dumps(hypotheses, ensure_ascii=False, indent=2)}

ã€è©•ä¾¡è¦³ç‚¹ã€‘
1. æ¤œè¨¼å¯èƒ½æ€§ï¼ˆBigQueryã§å®Ÿéš›ã«æ¸¬å®šã§ãã‚‹ã‹ï¼‰
2. æ¯”è¼ƒåŸºæº–ã®æ˜ç¢ºæ€§ï¼ˆä½•ã¨æ¯”è¼ƒã™ã‚‹ã‹ï¼‰
3. ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ï¼ˆçµæœãŒæ„æ€æ±ºå®šã«å½¹ç«‹ã¤ã‹ï¼‰
4. çµ±è¨ˆçš„å¦¥å½“æ€§ï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ãƒ»ãƒã‚¤ã‚¢ã‚¹ç­‰ï¼‰
5. å®Ÿè¡Œå¯èƒ½æ€§ï¼ˆãƒªã‚½ãƒ¼ã‚¹ãƒ»æ™‚é–“åˆ¶ç´„ï¼‰

ã€å‡ºåŠ›å½¢å¼ã€‘
```json
[
  {{
    "hypothesis_id": "H001",
    "strengths": ["å¼·ã¿"],
    "weaknesses": ["å¼±ç‚¹"],
    "improvement_suggestions": ["å…·ä½“çš„æ”¹å–„æ¡ˆ"],
    "feasibility_score": 1-10
  }}
]
```
"""
        
        response = get_openai_response(evaluation_prompt)
        return self._extract_json(response)
    
    def refine_hypotheses(self, original_hypotheses: List[Dict], evaluations: List[Dict]) -> List[Dict]:
        """ã‚¹ãƒ†ãƒƒãƒ—3: æ”¹è‰¯ç‰ˆç”Ÿæˆ"""
        refinement_prompt = f"""
è©•ä¾¡çµæœã‚’åŸºã«ä»®èª¬ã‚’æ”¹è‰¯ã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã®ä»®èª¬ã€‘
{json.dumps(original_hypotheses, ensure_ascii=False, indent=2)}

ã€è©•ä¾¡çµæœã€‘
{json.dumps(evaluations, ensure_ascii=False, indent=2)}

ã€æ”¹è‰¯è¦æ±‚ã€‘
- å¼±ç‚¹ã‚’ä¿®æ­£
- æ”¹å–„ææ¡ˆã‚’åæ˜ 
- ã‚ˆã‚Šå…·ä½“çš„ã§æ¤œè¨¼å¯èƒ½ã«
- æ¯”è¼ƒåŸºæº–ã‚’æ˜ç¢ºåŒ–

ã€å‡ºåŠ›å½¢å¼ã€‘
```json
[
  {{
    "id": "H001_refined",
    "original_hypothesis": "å…ƒã®ä»®èª¬",
    "refined_hypothesis": "æ”¹è‰¯ã•ã‚ŒãŸä»®èª¬",
    "improvements_made": ["è¡Œã£ãŸæ”¹è‰¯"],
    "comparison_baseline": "æ˜ç¢ºãªæ¯”è¼ƒåŸºæº–",
    "verification_method": "æ¤œè¨¼æ–¹æ³•"
  }}
]
```
"""
        
        response = get_openai_response(refinement_prompt)
        return self._extract_json(response)
    
    def final_validation(self, refined_hypotheses: List[Dict]) -> List[Dict]:
        """ã‚¹ãƒ†ãƒƒãƒ—4: æœ€çµ‚æ¤œè¨¼"""
        validation_prompt = f"""
æ”¹è‰¯ã•ã‚ŒãŸä»®èª¬ã®æœ€çµ‚æ¤œè¨¼ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€æ”¹è‰¯ä»®èª¬ã€‘
{json.dumps(refined_hypotheses, ensure_ascii=False, indent=2)}

ã€æ¤œè¨¼é …ç›®ã€‘
1. æ¤œè¨¼å¯èƒ½æ€§: BigQueryã§å®Ÿè¡Œå¯èƒ½ã‹
2. æ˜ç¢ºæ€§: æ›–æ˜§ã•ãŒãªã„ã‹
3. ä¾¡å€¤: ãƒ“ã‚¸ãƒã‚¹æ”¹å–„ã«ç¹‹ãŒã‚‹ã‹
4. å®Ÿç¾æ€§: ç¾å®Ÿçš„ã«å®Ÿè¡Œã§ãã‚‹ã‹

ã€å‡ºåŠ›ã€‘
å„ä»®èª¬ã«ã¤ã„ã¦åˆæ ¼/ä¸åˆæ ¼ã‚’åˆ¤å®šã—ã€æœ€çµ‚ç‰ˆã‚’å‡ºåŠ›ã€‚

```json
[
  {{
    "id": "H001_final",
    "hypothesis": "æœ€çµ‚ä»®èª¬",
    "validation_status": "pass/fail",
    "confidence_score": 1-10,
    "business_impact": "æœŸå¾…ã•ã‚Œã‚‹ä¾¡å€¤"
  }}
]
```
"""
        
        response = get_openai_response(validation_prompt)
        return self._extract_json(response)
    
    def iterative_refinement_process(self, schema_text: str, data_exploration: str) -> List[Dict]:
        """å®Œå…¨ãªæ®µéšçš„æ”¹è‰¯ãƒ—ãƒ­ã‚»ã‚¹"""
        
        print("ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—1: åˆæœŸä»®èª¬ç”Ÿæˆ")
        hypotheses = self.generate_initial_hypotheses(schema_text, data_exploration)
        print(f"ç”Ÿæˆã•ã‚ŒãŸåˆæœŸä»®èª¬: {len(hypotheses)}ä»¶")
        
        # è¤‡æ•°å›ã®æ”¹è‰¯ãƒ©ã‚¦ãƒ³ãƒ‰
        for round_num in range(self.refinement_rounds):
            print(f"ğŸ”„ ãƒ©ã‚¦ãƒ³ãƒ‰{round_num + 1}: æ‰¹åˆ¤çš„è©•ä¾¡ã¨æ”¹è‰¯")
            
            # æ‰¹åˆ¤çš„è©•ä¾¡
            evaluations = self.critical_evaluation(hypotheses)
            print(f"è©•ä¾¡å®Œäº†: {len(evaluations)}ä»¶")
            
            # æ”¹è‰¯
            refined = self.refine_hypotheses(hypotheses, evaluations)
            print(f"æ”¹è‰¯å®Œäº†: {len(refined)}ä»¶")
            
            # æ¬¡ãƒ©ã‚¦ãƒ³ãƒ‰ã®ãŸã‚ã«æ›´æ–°
            hypotheses = refined
        
        print("âœ… ã‚¹ãƒ†ãƒƒãƒ—4: æœ€çµ‚æ¤œè¨¼")
        final_hypotheses = self.final_validation(hypotheses)
        print(f"æœ€çµ‚ä»®èª¬: {len(final_hypotheses)}ä»¶")
        
        return final_hypotheses
    
    def _extract_json(self, response: str) -> List[Dict]:
        """JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹æŠ½å‡º"""
        import re
        
        json_match = re.search(r'```json\s*(\[.*?\])\s*```', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        
        json_match = re.search(r'(\[.*?\])', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        
        return []

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    refiner = IterativeHypothesisRefiner()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰
    from src.config import SCHEMA_TXT_FILE, DATA_EXPLORATION_FILE
    
    with open(SCHEMA_TXT_FILE, 'r', encoding='utf-8') as f:
        schema_text = f.read()
    
    with open(DATA_EXPLORATION_FILE, 'r', encoding='utf-8') as f:
        data_exploration = f.read()
    
    # æ®µéšçš„æ”¹è‰¯ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œ
    final_hypotheses = refiner.iterative_refinement_process(schema_text, data_exploration)
    
    # çµæœä¿å­˜
    with open('/Users/idenominoru/Desktop/AI_analyst/data/hypotheses/hypotheses_iterative.json', 'w', encoding='utf-8') as f:
        json.dump(final_hypotheses, f, ensure_ascii=False, indent=2)
    
    print("æ®µéšçš„æ”¹è‰¯ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†ï¼")